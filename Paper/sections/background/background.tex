\documentclass[../../submission.tex]{subfiles}
\begin{document}
\section{Background}
The gap between human communication and database interaction has been a persistent challenge in computer science. 
Users of information systems naturally express their information need in everyday language, yet databases require
precise, syntactically correct and structured queries - a mismatch that has fueled decades of research into natural language
interfaces to databases \cite{androutsopoulosNaturalLanguageInterfaces1995}.
Traditional keyword-based search systems often fail to capture the nuanced intent behind user queries,
particularly in e-commerce environments where user frustation with suboptimal search results can directly
impact business success \cite{manchandaIntentTermSelection2019}. This fundamental challenge has led to 
various approaches in bridging the gap between natural language and database queries over the past decades.

\subsection{Evolution of Natural Language Interfaces}
The journey of Natural Language Interfaces (NLIs) dates back to the 1960s with pioneering
systems like \textit{BASEBALL}, which translated natural language questions about baseball 
statistics into database queries \cite{greenBaseballAutomaticQuestionanswerer1961}. 
The development of \textit{LUNAR} \cite{woods1973progress} followed, helping NASA geologists query chemical analyses of lunar rocks.
Both operated in narrow domains, relying heavily on manually crafted rules and domain-specific knowledge \cite{popescuEtalTowardsTheoryOfNaturalLanguage}.
\\
By the early 2000s, systems like \textit{PRECISE} advanced the field by treating translation as a 
graph matching problem, achieving high precision for semantically tractable queries within a supported 
domain. However, such systems still required extensive manual engineering
and struggled with ambuigity.
\\
Current generation systems, powered by foundation models such as ChatGPT, 
have largely overcome these historical limitations, demonstrating broad 
language understanding with minimal engineering effort \cite{raffelExploringLimitsTransfer2023}.
In the context of e-commerce, these models can interpret complex queries like "cheap 
gaming laptop with high-quality webcam" by leveraging vast training data to infer 
intent and map it to database fields/columns. For example, such systems could dynamically link
"gaming" to attributes like high RAM or GPU performance, adressing user needs more intuitively
than static templates. Nonetheless, new challenges emerge, such as the lack of transparency 
in the output of these foundatin models and the need to ensure that generated queries are both 
semantically accurate and syntactically correct.
This is critical, as erroneous SQL queries cannot be executed, potentially resulting in a degraded user 
experience, where users encounter errors or fail to retrieve search results. These emerging issues 
highlight the need for research into transparent and reliable NL-to-SQL systems, particularly in domains 
like e-commerce where user satisfaction is paramount. 

\subsection{Current Approaches to NL-to-SQL}
The rise of deep learning has transformed NL-to-SQL translation from 
rule-based and statistical methods to neural network based approaches. Early systems
like Seq2SQL \cite{zhongSeq2SQLGeneratingStructured2017} used sequence-to-sequence models to generate SQL from natural language,
performing well on simple queries but struggling with complex ones involving multiple 
conditions or joins. Modern transformer-based models, such as those build on BERT and GPT-architecture,
improve accuaracy by incorporating schema linking and intermediate representation, as 
as seen in systems like RAT-SQL \cite{wangRATSQLRelationAwareSchema2021}. Tools like SQLAI.ai \cite{GenerateSQLQueries} exemplify this trend, leveraging large language models
to generate SQL queries from natural language inputs, with minimal user effort. However, SQLAI.ai 
introduces trade-offs: 1{)} it requires payment, 2{)} lacks transparency in its query generation process and 3{)}
functions primarily as a developer tool, prioritizing flexibility over safety or interpretability.
Nevertheless, these advances enable robust query generation across diverse 
schemas, yet challenges remain in ensuring transparency and handling ambiguous input-issues, which 
is critical for practical applications. As these techniques mature, their 
potential to enhance domain-specific systems, such as those in e-commerce, has sparked growing interest, bridging
the gap between technical innovation and real-world usability.

\subsection{Usability in NL-to-SQL Systems}
Usability is a cornerstone of effective human-computer interaction, especially 
in e-commerce, where intuitive and efficient search experiences can determine 
whether users complete a purchase or abandon their search altogether. 
Unlike traditional 
interfaces that force users to adapt to rigid keywords and filters, NL-to-SQL systems aim 
to reverse this dynamic by interpreting natural language. The success of such systems relies heavily on aligning with user expectations.

An important factor is interpreting diverse queries, from vague inputs like "good laptop" to precise ones 
like "16Gb Ram Laptop under 600€". Studies show that flexibility in handling such variaty is vital, 
as users rarely follow a single search query pattern \cite{manchandaIntentTermSelection2019}. Such system 
have to map these input to relevant database field using the context of the domain or available metadata
to ensure relevance. Another key aspect is feedback: when results miss the mark (for example, let the search-query 
be "gaming laptop"), clear feedback like "Did you mean high GPU performance?" - improve relevance 
and build trust by revealing the systems logic \cite{popescuEtalTowardsTheoryOfNaturalLanguage}, which is 
crucial in e-comerce settings to reduce frustation and to retain users.

Effective feedback naturally leads to the broader challenge of designing an interface that balances accessibility 
with functionality. Rather than burdening users with technical complexity, the system should deliver results in 
a way that feels intuitive for casual shoppers—e.g., prioritizing top matches based on intent—while allowing more 
experienced users to refine searches through additional prompts or guided options. This approach ensures a seamless 
experience across diverse audiences, minimizing search friction in a competitive e-commerce landscape. 
By prioritizing such usability principles, NL-to-SQL systems can pave the way for practical implementations, such 
as the interface we developed to explore these dynamics in a controlled user study, as detailed in the following section.

\end{document}